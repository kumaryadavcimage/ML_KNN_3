{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674e8b94-caf8-41da-9d59-2df3afc25783",
   "metadata": {},
   "source": [
    "#### Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ec5e0-3ea8-41bf-a776-619577355e8e",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Python code that implements the K-Nearest Neighbors (KNN) classifier on the Iris dataset using sklearn's load_iris function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1639134a-065b-4151-8431-5b28876c74f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Labels\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling (important for KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN classifier model (using 5 nearest neighbors by default)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d2a1f9-91be-40d9-8fe0-ed969d85213f",
   "metadata": {},
   "source": [
    "####\n",
    "Explanation:\n",
    "\n",
    "- Loading the Iris dataset: The load_iris() function from sklearn.datasets provides the Iris dataset, which contains 150 samples of iris flowers, each with 4 features and 3 target classes.\n",
    "\n",
    "- Splitting the dataset: The data is split into training and testing sets using the train_test_split() function. Here, 80% of the data is used for training and 20% for testing.\n",
    "\n",
    "- Feature scaling: KNN is distance-based, so it's important to scale the features to ensure each feature contributes equally to the distance metric. The StandardScaler() is used to standardize the features.\n",
    "\n",
    "- KNN model creation: The KNN classifier is created using KNeighborsClassifier(), and the number of neighbors is set to 5 by default.\n",
    "\n",
    "- Model training and prediction: The fit() method trains the KNN model on the training data, and predict() makes predictions on the test data.\n",
    "\n",
    "- Model evaluation: The model's accuracy, confusion matrix, and classification report are displayed using accuracy_score(), confusion_matrix(), and classification_report()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb6f54-2ab1-4fff-9a5e-551014b572d0",
   "metadata": {},
   "source": [
    "#### Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebc115-34b6-4888-a6d9-8b5d8be785ca",
   "metadata": {},
   "source": [
    "#### solve\n",
    " Python code that implements the K-Nearest Neighbors (KNN) regressor algorithm on the Boston housing dataset using sklearn's load_boston function. However, it's worth noting that the load_boston dataset is deprecated due to ethical concerns regarding the dataset, so I'll provide an alternative using fetch_openml to get the Boston housing data from OpenML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1d8d58-f63b-48e5-8fbe-25345262c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 20.61\n",
      "R^2 Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "boston = fetch_openml(name='boston', version=1)\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)  # Features\n",
    "y = pd.Series(boston.target, name='MEDV')  # Target variable (median value of owner-occupied homes in $1000s)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling (important for KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN regressor model (using 5 nearest neighbors by default)\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0074f7e-8b81-4194-b9fc-0cc1faa5b69a",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Loading the Boston housing dataset: The dataset is fetched using fetch_openml() instead of load_boston(). The features and target variable are extracted into X and y, respectively.\n",
    "\n",
    "- Splitting the dataset: The data is split into training and testing sets using the train_test_split() function, where 80% of the data is used for training and 20% for testing.\n",
    "\n",
    "- Feature scaling: The features are standardized using StandardScaler(), which is important for KNN since it is sensitive to the scale of the data.\n",
    "\n",
    "- KNN regressor model creation: A KNN regressor model is created using KNeighborsRegressor(), with the number of neighbors set to 5.\n",
    "\n",
    "- Model training and prediction: The fit() method trains the KNN model on the training data, and the predict() method is used to make predictions on the test data.\n",
    "\n",
    "- Model evaluation: The model's performance is evaluated using Mean Squared Error (MSE) and RÂ² score. The mean_squared_error() and r2_score() functions calculate these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4ed41-0733-403c-96a6-a30e2ccad774",
   "metadata": {},
   "source": [
    "#### Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using cross-validation on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d4994-19d2-4683-8dde-85e328aa7b3a",
   "metadata": {},
   "source": [
    "#### solve\n",
    "To find the optimal value of K for the KNN classifier using cross-validation, we can use GridSearchCV from sklearn.model_selection. Here's a Python code snippet that implements this approach on the Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4670e26c-06c4-4626-b210-40b02f25b429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal value of K is: 3\n",
      "Accuracy with K=3: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create a dictionary of possible values for K\n",
    "param_grid = {'n_neighbors': range(1, 31)}  # K from 1 to 30\n",
    "\n",
    "# Use GridSearchCV to find the optimal value of K\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best K value\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "print(f\"The optimal value of K is: {best_k}\")\n",
    "\n",
    "# Train the KNN model with the optimal K\n",
    "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = knn_best.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with K={best_k}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbfa3db-5eb4-43cd-aedf-26a976cab334",
   "metadata": {},
   "source": [
    "####\n",
    "Explanation:\n",
    "- Data Loading: The load_iris() function loads the Iris dataset.\n",
    "\n",
    "- Data Splitting: The dataset is split into training (80%) and testing (20%) sets using train_test_split().\n",
    "\n",
    "- Feature Scaling: The features are standardized using StandardScaler() to ensure that all features contribute equally.\n",
    "\n",
    "- K Range: The param_grid dictionary contains a range of values for n_neighbors (K) from 1 to 30.\n",
    "\n",
    "- Cross-Validation: GridSearchCV performs cross-validation with 5 folds (cv=5) to find the best K value by checking accuracy for each K.\n",
    "\n",
    "- Best K and Final Evaluation: After finding the optimal K, the model is retrained with that value, and the accuracy on the test set is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6134f68-cfc2-404a-b5b7-ab56cbe50ff9",
   "metadata": {},
   "source": [
    "#### Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b111c26-c0d0-4947-a48c-85df1ccea573",
   "metadata": {},
   "source": [
    "#### solve\n",
    " Python code snippet that implements the K-Nearest Neighbors (KNN) regressor algorithm on the Boston housing dataset using feature scaling. Since the load_boston function is deprecated due to ethical concerns, we will use fetch_openml to load the dataset from OpenML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc223d9-f1e5-4fca-9750-afd8e0f515ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 20.61\n",
      "R^2 Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Boston housing dataset\n",
    "boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
    "X = boston.data  # Features\n",
    "y = boston.target  # Target variable (median value of owner-occupied homes in $1000s)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling (important for KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN regressor model (using 5 nearest neighbors by default)\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003207b-92d5-460d-ab34-34dd00a1512f",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "- Loading the Dataset: The Boston housing dataset is loaded using fetch_openml(). The as_frame=True parameter ensures that the data is returned as a pandas DataFrame, making it easier to work with.\n",
    "\n",
    "- Data Splitting: The dataset is split into training (80%) and testing (20%) sets using the train_test_split() function.\n",
    "\n",
    "- Feature Scaling: The features are standardized using StandardScaler(), which is crucial for KNN since it is sensitive to the scale of the data.\n",
    "\n",
    "- KNN Regressor Model: A KNN regressor model is created using KNeighborsRegressor(), with the number of neighbors set to 5.\n",
    "\n",
    "- Training and Prediction: The model is trained using the training data with the fit() method, and predictions are made on the test set with the predict() method.\n",
    "\n",
    "- Model Evaluation: The model's performance is evaluated using Mean Squared Error (MSE) and RÂ² score to quantify how well the model predicts housing prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e39f66-bbf6-4bd0-b54d-7e4755a50950",
   "metadata": {},
   "source": [
    "#### Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on load_iris dataset in sklearn.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3733c411-cfbe-4ac5-b68b-c394bba62636",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Python code snippet that implements the K-Nearest Neighbors (KNN) classifier algorithm with weighted voting on the Iris dataset using sklearn. In weighted voting, the contributions of neighbors to the prediction are weighted based on their distances, with closer neighbors having a larger influence on the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ca526a9-2f75-4f81-980e-05b2c4db006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Labels\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN classifier model with weighted voting\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97abf9c-12e0-46ee-8453-8f30df7dc0a5",
   "metadata": {},
   "source": [
    "####\n",
    "Explanation:\n",
    "\n",
    "- Loading the Iris Dataset: The Iris dataset is loaded using load_iris(), which provides both the feature data (X) and the target labels (y).\n",
    "\n",
    "- Data Splitting: The dataset is split into training (80%) and testing (20%) sets using the train_test_split() function.\n",
    "\n",
    "- Feature Scaling: The features are standardized using StandardScaler(), which is important for KNN since it is sensitive to the scale of the data.\n",
    "\n",
    "- KNN Classifier with Weighted Voting: A KNN classifier is created using KNeighborsClassifier(), with n_neighbors set to 5 and weights='distance' to enable weighted voting based on the distances of the neighbors.\n",
    "\n",
    "- Model Training and Prediction: The model is trained on the training data using the fit() method, and predictions are made on the test data using the predict() method.\n",
    "\n",
    "- Model Evaluation: The model's accuracy, confusion matrix, and classification report are printed to evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8010cdb9-8fa0-4660-bc45-b6e3e6cd2947",
   "metadata": {},
   "source": [
    "#### Q6. Implement a function to standardise the features before applying KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf8fc8-4b4f-433f-adf6-9d6e1e610ac6",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Below is a Python function that standardizes the features of a dataset before applying the KNN classifier. This function uses StandardScaler from sklearn.preprocessing to scale the features. The function takes in the features and the target labels, splits the data into training and testing sets, standardizes the features, and then fits a KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e201e1cc-20b5-4dcb-9f46-e19211847a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def standardize_and_knn(X, y, n_neighbors=5, test_size=0.2, random_state=42):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the scaler on the training data and transform both train and test data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Create the KNN classifier with weighted voting\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights='distance')\n",
    "\n",
    "    # Train the model\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the Iris dataset\n",
    "    iris = load_iris()\n",
    "    X = iris.data  # Features\n",
    "    y = iris.target  # Labels\n",
    "\n",
    "    # Call the function\n",
    "    standardize_and_knn(X, y, n_neighbors=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e870eb3-33ff-4d03-8939-166c21b20a18",
   "metadata": {},
   "source": [
    "####\n",
    "Explanation of the Function:\n",
    "\n",
    "- Function Definition: The function standardize_and_knn() takes four parameters:\n",
    "\n",
    "x : The features of the dataset.\n",
    "\n",
    "y : The taget labels.\n",
    "\n",
    "N-neighbors : The proportion of the dataset to include in the test split (default is 5).\n",
    "\n",
    "test_size : The proportion of the dataset to include in the test split(default is 0.2)\n",
    "\n",
    "random_state: Controls the shuffling applied to the data before applying the split (default is 42).\n",
    "\n",
    "- Data Splitting: The dataset is split into training and testing sets using train_test_split().\n",
    "\n",
    "- Standardization: The StandardScaler is used to standardize the training data, and the same transformation is applied to the test data.\n",
    "\n",
    "- KNN Classifier Creation: A KNN classifier is created with weighted voting enabled.\n",
    "\n",
    "- Model Training and Prediction: The model is trained on the standardized training data, and predictions are made on the standardized test data.\n",
    "\n",
    "- Model Evaluation: The function prints the accuracy, confusion matrix, and classification report to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f556a43-56c2-432d-9de5-74f3f0f1e8da",
   "metadata": {},
   "source": [
    "#### Q7. Write a Python function to calculate the euclidean distance between two points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ee4d5-db84-4913-aa52-3ea26aa5b2a8",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Python function that calculates the Euclidean distance between two points in n-dimensional space. The function takes two lists or tuples representing the coordinates of the two points and returns the distance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf724081-f042-4d8f-b2e0-9940fa41ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean distance between (3, 4) and (0, 0) is: 5.00\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: A list or tuple representing the coordinates of the first point.\n",
    "    - point2: A list or tuple representing the coordinates of the second point.\n",
    "\n",
    "    Returns:\n",
    "    - Distance: The Euclidean distance between point1 and point2.\n",
    "    \"\"\"\n",
    "    # Ensure both points have the same dimension\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"Both points must have the same number of dimensions.\")\n",
    "\n",
    "    # Calculate the sum of squared differences\n",
    "    distance = math.sqrt(sum((a - b) ** 2 for a, b in zip(point1, point2)))\n",
    "\n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    point_a = (3, 4)\n",
    "    point_b = (0, 0)\n",
    "\n",
    "    distance = euclidean_distance(point_a, point_b)\n",
    "    print(f\"The Euclidean distance between {point_a} and {point_b} is: {distance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7483af9-815b-4592-a707-ffbd94dc1278",
   "metadata": {},
   "source": [
    "####\n",
    "Explanation of the Function:\n",
    "Function Definition: The function euclidean_distance() takes two parameters, point1 and point2, which should be lists or tuples representing the coordinates of the two points.\n",
    "\n",
    "Dimension Check: The function checks if both points have the same number of dimensions. If not, it raises a ValueError.\n",
    "\n",
    "Distance Calculation: The function calculates the Euclidean distance using the formula:\n",
    "\n",
    "          Distance = root Sigma(x1-x2)^2\n",
    "\n",
    "It uses a generator expression to compute the squared differences between corresponding coordinates of the two points, sums them up, and then takes the square root.\n",
    "\n",
    "Return Value: The function returns the calculated distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36097364-67f9-4d4b-a4a3-1f96e68372e6",
   "metadata": {},
   "source": [
    "#### Q8. Write a Python function to calculate the manhattan distance between two points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa48e1-0ed8-4d8a-bca5-4f4f868f12b9",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Python function that calculates the Manhattan distance between two points in n-dimensional space. The Manhattan distance (also known as the L1 distance or taxicab distance) is the sum of the absolute differences of their coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7056bd80-6bef-4126-9738-69d6a6614ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Manhattan distance between (3, 4) and (1, 1) is: 5\n"
     ]
    }
   ],
   "source": [
    "def manhattan_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Manhattan distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "    - point1: A list or tuple representing the coordinates of the first point.\n",
    "    - point2: A list or tuple representing the coordinates of the second point.\n",
    "\n",
    "    Returns:\n",
    "    - Distance: The Manhattan distance between point1 and point2.\n",
    "    \"\"\"\n",
    "    # Ensure both points have the same dimension\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"Both points must have the same number of dimensions.\")\n",
    "\n",
    "    # Calculate the sum of absolute differences\n",
    "    distance = sum(abs(a - b) for a, b in zip(point1, point2))\n",
    "\n",
    "    return distance\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    point_a = (3, 4)\n",
    "    point_b = (1, 1)\n",
    "\n",
    "    distance = manhattan_distance(point_a, point_b)\n",
    "    print(f\"The Manhattan distance between {point_a} and {point_b} is: {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec883d48-20bc-4021-9d6f-60de87f62b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "Explanation of the Function:\n",
    "Function Definition: The function manhattan_distance() takes two parameters, point1 and point2, which should be lists or tuples representing the coordinates of the two points.\n",
    "\n",
    "Dimension Check: The function checks if both points have the same number of dimensions. If not, it raises a ValueError.\n",
    "\n",
    "Distance Calculation: The function calculates the Manhattan distance using the formula:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
